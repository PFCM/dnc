# Copyright 2017 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
"""A repeat copy task."""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import collections
import random
import string
import numpy as np
import sonnet as snt
import tensorflow as tf

DatasetTensors = collections.namedtuple('DatasetTensors', ('observations',
                                                           'target', 'mask'))


def masked_softmax_cross_entropy(logits,
                                 target,
                                 mask,
                                 time_average=False,
                                 log_prob_in_bits=False):
  """Adds ops to graph which compute the (scalar) NLL of the target sequence.

  The logits parametrize softmax distributions per time-step and
  per batch element, and irrelevant time/batch elements are masked out by the
  mask tensor.

  Args:
    logits: `Tensor` of activations.
    target: time-major integer `Tensor` of target.
    mask: time-major `Tensor` to be multiplied elementwise with cost T x B cost
        masking out irrelevant time-steps.
    time_average: optionally average over the time dimension (sum by default).
    log_prob_in_bits: iff True express log-probabilities in bits (default nats).

  Returns:
    A `Tensor` representing the log-probability of the target.
  """
  xent = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=target,
                                                        logits=logits)
  loss_time_batch = xent
  loss_batch = tf.reduce_sum(loss_time_batch * mask, axis=0)

  batch_size = tf.cast(tf.shape(logits)[1], dtype=loss_time_batch.dtype)

  if time_average:
    mask_count = tf.reduce_sum(mask, axis=0)
    loss_batch /= (mask_count + np.finfo(np.float32).eps)

  loss = tf.reduce_sum(loss_batch) / batch_size
  if log_prob_in_bits:
    loss /= tf.log(2.)

  return loss


def intstring_readable(data, batch_size, vocab, model_output=None,
                       whole_batch=False):
  """Produce a human readable representation of the sequences in data.

  Args:
    data: data to be visualised
    batch_size: size of batch
    vocab: a dict of int->char to translate to something more readable.
    model_output: optional model output tensor to visualize alongside data.
    whole_batch: whether to visualise the whole batch. Only the first sample
        will be visualized if False

  Returns:
    A string used to visualise the data batch
  """

  def _readable(datum):
    return '+ ' + ''.join([vocab[x] for x in datum]) + ' +'

  obs_batch = data.observations
  targ_batch = data.target
  if model_output is not None:
    model_output = np.argmax(model_output, axis=2)

  iterate_over = xrange(batch_size) if whole_batch else xrange(1)

  batch_strings = []
  for batch_index in iterate_over:
    obs = obs_batch[:, batch_index]
    targ = targ_batch[:, batch_index]

    obs_channel_string = _readable(obs)
    targ_channel_string = _readable(targ)

    readable_obs = 'Observations:\n' + obs_channel_string
    readable_targ = 'Targets:\n' + targ_channel_string
    strings = [readable_obs, readable_targ]

    if model_output is not None:
      output = model_output[:, batch_index]
      output_string = _readable(output)
      strings.append('Model Output:\n' + output_string)

    batch_strings.append('\n\n'.join(strings))

  return '\n' + '\n\n\n\n'.join(batch_strings)


class VariableAssignment(snt.AbstractModule):
  """Sequence data generator for the task of variable assignment.
  As defined in https://arxiv.org/pdf/1602.03032.pdf

  When called, an instance of this class will return a tuple of tensorflow ops
  (obs, targ, mask), representing an input sequence, target sequence, and
  binary mask. Each of these ops produces tensors whose first two dimensions
  represent sequence position and batch index respectively. The value in
  mask[t, b] is equal to 1 iff a prediction about targ[t, b, :] should be
  penalized and 0 otherwise.

  Input observations are generated by the following grammar like rules:
  - `input_sequence := (1-4 assigments)(1 query)"."`
  - `assignment := "s("varname","value")"`
  - `varname := 1-4 random lowercase latin characters`
  - `value := 1 random lowercase latin character`
  - `query := "q("varname")"

  with the constraint the the varname used in the query needs to be one of
  those presented in an earlier assignment.

  The target is all zeros except for the final step, which is the appropriate
  character.

  We are dealing one character at a time and there are four special characters
  ("(", ")" and ","), so the inputs are integers between 0 and 28 inclusive.
  It is up to the model to decide whether to convert to one-hot or use for
  embedding lookup.

  An example sequence is shown below, translated to characters
  ```none
  Note: blank space in the targets will probably be zeros, (which is in fact
  the character '.'), but will be masked out in the loss.

  time ------------------------------->

                +---------------------+
  mask:         |000000000000000000001|
                +---------------------+

                +---------------------+
  target:       |                    a|
                +---------------------+

                +---------------------+
  observation:  |s(ml,a)s(qds,d)q(ml).|
                +---------------------+
  ```

  The number of assignments is uniformly distributed between 1 and 4
  (inclusive).

  In order for all the sequences in a minibatch to be the same length they are
  padded appropriately with zeros at the end. As the mask is also padded, this
  will make no difference to the loss.

  Helpers are provided to compute the loss across a batch, which is just the
  softmax cross entropy between some prediction logits and the network's output
  at the appropriate time.
  """

  def __init__(
      self,
      batch_size,
      log_prob_in_bits=False,
      name='variable_assignment'):
    """Creates an instance of Variable Assignment task.

    Args:
      batch_size: Minibatch size per realization.
      log_prob_in_bits: By default, log probabilities are expressed in units of
        nats. If true, express log probabilities in bits.
      name: A name for the generator instance (for name scope purposes).
    """
    super(VariableAssignment, self).__init__(name)

    self._batch_size = batch_size
    self._log_prob_in_bits = log_prob_in_bits
    chars = ['.', '(', ')', ','] + list(string.ascii_lowercase)
    self._vocab = {char: i for i, char in enumerate(chars)}

  @property
  def log_prob_in_bits(self):
    return self._log_prob_in_bits

  @property
  def batch_size(self):
    return self._batch_size

  @property
  def target_size(self):
    return len(self._vocab)

  @property
  def vocabulary(self):
    return self._vocab

  @property
  def inverse_vocabulary(self):
    return {i: char for char, i in self._vocab.items()}

  def _generate_assignment(self):
    """return (key, value) for a random assignment"""
    key = [self._vocab[random.choice(string.ascii_lowercase)]
           for _ in xrange(np.random.randint(1, 4))]
    value = self._vocab[random.choice(string.ascii_lowercase)]
    return (key, value)

  def _fill_query(self, query):
    """create integers for a query from (key, value) tuple. Key is a list,
    value is not"""
    return [self._vocab['q'], self._vocab['(']] + query[0] + [self._vocab[')']]

  def _fill_assignment(self, assignment):
    """create integers for an assignment from (key, value) tuple. Key is a list,
    value is not."""
    assg = [self._vocab['s'], self._vocab['(']]
    assg += assignment[0]
    assg += [self._vocab[','], assignment[1], self._vocab[')']]
    return assg

  def _generate_batch(self):
    """generate a batch of data and return as np arrays"""
    batch_seqs = []
    for _ in xrange(self.batch_size):
      num_assignments = np.random.randint(1, 5)
      assignments = [self._generate_assignment()
                     for _  in xrange(num_assignments)]
      query = random.choice(assignments)
      assignments = [self._fill_assignment(assg) for assg in assignments]
      observation = [item for assg in assignments for item in assg]
      observation += self._fill_query(query) + [self._vocab['.']]
      target = ([0] * (len(observation) - 1)) + [query[1]]
      mask = ([0.] * (len(observation) - 1)) + [1.]
      batch_seqs.append((observation, target, mask))
    # pad them
    longest_seq = max([len(item[0]) for item in batch_seqs])
    padded_batch_seqs = []
    for obs, targ, mask in batch_seqs:
      pad_steps = longest_seq - len(obs)
      if pad_steps > 0:
        padding = [0] * pad_steps
        obs += padding
        targ += padding
        mask += padding
      padded_batch_seqs.append((obs, targ, mask))

    all_observations = [item[0] for item in padded_batch_seqs]
    all_targets = [item[1] for item in padded_batch_seqs]
    all_masks = [item[2] for item in padded_batch_seqs]

    all_observations = np.array(all_observations, dtype=np.int32)
    all_targets = np.array(all_targets, dtype=np.int32)
    all_masks = np.array(all_masks, dtype=np.float32)
    # output should be [time, batch]
    all_observations = all_observations.transpose()
    all_targets = all_targets.transpose()
    all_masks = all_masks.transpose()

    return all_observations, all_targets, all_masks

  def _build(self):
    """Implements build method which adds ops to graph."""
    # because we have to create a variable number of variable sized structures,
    # it is easiest (aka. fastest to implement) to do it in a python function
    # and wrap it in tf.py_func
    obs, targ, mask = tf.py_func(self._generate_batch,
                                 [],
                                 (tf.int32, tf.int32, tf.float32),
                                 stateful=True)  # or we get the same seqs
    obs = tf.reshape(obs, [-1, self._batch_size])
    targ = tf.reshape(targ, [-1, self._batch_size])
    mask = tf.reshape(mask, [-1, self._batch_size])

    return DatasetTensors(obs, targ, mask)

  def cost(self, logits, targ, mask):
    return masked_softmax_cross_entropy(
        logits,
        targ,
        mask,
        time_average=True,
        log_prob_in_bits=self.log_prob_in_bits)

  def to_human_readable(self, data, model_output=None, whole_batch=False):
    return intstring_readable(data, self.batch_size, self.inverse_vocabulary,
                              model_output, whole_batch)
